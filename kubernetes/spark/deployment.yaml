apiVersion: apps/v1
kind: Deployment
metadata:
  name: spark-top
spec:
  replicas: 1
  selector:
    matchLabels:
      app: spark-top
  template:
    metadata:
      labels:
        app: spark-top
    spec:
      nodeSelector:
        cloud.google.com/gke-nodepool: spark-pool
      tolerations:
        - key: "dedicated"
          operator: "Equal"
          value: "spark"
          effect: "NoSchedule"
      containers:
        - name: spark-top
          image: a92340a/spark-base:0.3
          ports:
            - containerPort: 8080
            - containerPort: 7077
          volumeMounts:
            - mountPath: /opt/workspace
              name: workspace-volume
            # - mountPath: /app
            #   name: app-volume # 'data_consumer.py'
          envFrom:
            - configMapRef:
                name: postgres-config
          env:
            - name: SPARK_MODE
              value: master
          # envFrom:
          #   - secretRef:
          #       name: postgres-secrets

      volumes:
        - name: workspace-volume
          emptyDir: {}
        # - name: app-volume
        #   configMap:
        #     name: data-consumer-config # 'data_consumer.py'
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: spark-bottom
spec:
  replicas: 1
  selector:
    matchLabels:
      app: spark-bottom
  template:
    metadata:
      labels:
        app: spark-bottom
    spec:
      nodeSelector:
        cloud.google.com/gke-nodepool: spark-pool
      tolerations:
        - key: "dedicated"
          operator: "Equal"
          value: "spark"
          effect: "NoSchedule"
      containers:
        - name: spark-bottom
          image: a92340a/spark-base:0.3
          securityContext:
            runAsUser: 0
          ports:
            - containerPort: 8081
          command:
            - "/opt/bitnami/scripts/spark/entrypoint.sh"
          args:
            - "spark-class"
            - "org.apache.spark.deploy.worker.Worker"
            - "spark://spark-master-service:7077"
          # envFrom:
          #   - secretRef:
          #       name: postgres-secrets
          envFrom:
            - configMapRef:
                name: postgres-config
          env:
            - name: SPARK_MODE
              value: worker
            - name: SPARK_WORKER_CORES
              value: "1"
            - name: SPARK_WORKER_MEMORY
              value: "2g"
            - name: SPARK_MASTER_HOST
              value: spark-master-service
            - name: SPARK_MASTER
              value: "spark://spark-master-service:7077"
          volumeMounts:
            - name: workspace-volume
              mountPath: /opt/workspace
            - name: spark-env
              mountPath: /opt/bitnami/spark/conf/spark-env.sh
              subPath: spark-env.sh
            # - mountPath: /app
            #   name: app-volume #  'data_consumer.py'
      volumes:
        - name: workspace-volume
          emptyDir: {}
        - name: spark-env
          configMap:
            name: spark-env-config
        # - name: app-volume
        #   configMap:
        #     name: data-consumer-config # 'data_consumer.py'
